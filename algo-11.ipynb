{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given Parameters\n",
    "transmission_rate = [500, 1000, 1500, 2000, 2500, 3000]  # in kb/s\n",
    "num_devices_list = [50, 100, 150, 200, 250, 300]\n",
    "task_data = [5, 10, 15, 20, 25, 30, 35, 40, 45]  # in Mbit\n",
    "max_delay = 0.5  # in seconds\n",
    "device_computing_capacity = [0.5, 1]  # in GHz\n",
    "num_of_mecs = 10\n",
    "mec_computing_capacity = 8  # in GHz\n",
    "transmission_power = 4  # in Watts\n",
    "\n",
    "# Constants\n",
    "H_m = 1e-96  # Consumption factor of electricity\n",
    "y_nt = 1e-6  # Weighted factor of local time cost\n",
    "y_ne = 1e-12  # Weighted factor of local energy consumption\n",
    "e_m = 1e-7  # Energy required to calculate a single bit of task data for MEC server\n",
    "noise_power_spectral_density = 1e-9  # in Watts/Hz\n",
    "channel_gain = 2e-10  # \n",
    "path_loss_index = 4  # Typical urban area path loss exponent\n",
    "bandwidth = 1e9  # 1 MHz bandwidth\n",
    "max_energy = 1000  # in Joules\n",
    "clock_period_range = (800, 1200)  # cycles per bit\n",
    "penalty_factor = 10 ** -2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(x, task_data, transmission_power, bandwidth, noise_power_spectral_density, device_computing_capacity, mec_computing_capacity, apply_penalty=True):\n",
    "    clock_period = np.mean(clock_period_range)  # Average clock period for simplicity\n",
    "\n",
    "    # Initialize variables to avoid UnboundLocalError\n",
    "    transmission_time = 0\n",
    "    mec_task_execution_time = 0\n",
    "\n",
    "    if x == 0:  # Local computation\n",
    "        local_time_cost = task_data / (device_computing_capacity * 1e9)  # Converting GHz to Hz\n",
    "        local_time_cost *= clock_period  # Adjust for clock period per bit\n",
    "        local_energy_cost = H_m * (device_computing_capacity**2) * task_data\n",
    "        total_energy_cost = local_energy_cost\n",
    "    else:  # Edge server computation\n",
    "        transmission_time = task_data / (bandwidth * np.log2(1 + (transmission_power * channel_gain) / (noise_power_spectral_density * bandwidth)))\n",
    "        mec_task_execution_time = task_data / (mec_computing_capacity * 1e9) * clock_period  # Converting GHz to Hz and adjusting for clock period\n",
    "        mec_energy_cost = transmission_power * transmission_time + e_m * task_data\n",
    "        total_energy_cost = mec_energy_cost\n",
    "\n",
    "    # Directly integrate energy and time cost into total cost\n",
    "    total_cost = y_nt * (transmission_time + mec_task_execution_time) + y_ne * total_energy_cost\n",
    "\n",
    "    # Apply a severe penalty if the energy cost exceeds the maximum allowed and apply_penalty is True\n",
    "    if total_energy_cost > max_energy and apply_penalty:\n",
    "        total_cost += (total_energy_cost - max_energy) * penalty_factor  # Adjust the penalty factor as necessary\n",
    "\n",
    "    return total_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "class QPSO:\n",
    "    def __init__(self, num_devices, max_iter, task_data):\n",
    "        self.num_devices = num_devices\n",
    "        self.max_iter = max_iter\n",
    "        self.task_data = np.array(task_data) * 1e6  # Convert Mbit to bits for task sizes\n",
    "        self.X = np.random.randint(2, size=(num_devices, max_iter))  # Initial binary decisions for each device\n",
    "        \n",
    "        # Initialize Personal best decisions and their fitness\n",
    "        self.P = np.zeros((num_devices, 1), dtype=int)\n",
    "        self.P_fitness = np.full(num_devices, np.inf)\n",
    "\n",
    "        # Initialize global best decision and its fitness\n",
    "        self.g = np.zeros(num_devices, dtype=int)  # Placeholder, will be updated in evaluate_initial_decisions_parallel\n",
    "        self.g_fitness = np.inf  # Important: initialize g_fitness before evaluate_initial_decisions_parallel\n",
    "\n",
    "        # Parallel evaluation of initial decisions to find personal bests\n",
    "        self.evaluate_initial_decisions_parallel()\n",
    "\n",
    "        # Initialize global best decision set\n",
    "        self.g = self.X[:, 0]\n",
    "        self.g_fitness = np.min(self.P_fitness)  # Use the best of the initial personal bests\n",
    "        g_index = np.argmin(self.P_fitness)\n",
    "        self.g = self.X[:, g_index]\n",
    "\n",
    "    def evaluate_fitness_parallel(self, tasks):\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            \n",
    "            # Create a mapping of future to (i, t) pair\n",
    "            future_to_it = {}\n",
    "            \n",
    "            for i, (task_size, device_capacity, t) in enumerate(tasks):\n",
    "                future = executor.submit(fitness_function, self.X[i, t], task_size, transmission_power,\n",
    "                                        bandwidth, noise_power_spectral_density, device_capacity, mec_computing_capacity)\n",
    "                future_to_it[future] = (i, t)\n",
    "\n",
    "            for future in as_completed(future_to_it):\n",
    "                i, t = future_to_it[future]\n",
    "                current_fitness = future.result()\n",
    "\n",
    "                # Update personal and potentially global best\n",
    "                if current_fitness < self.P_fitness[i]:\n",
    "                    self.P[i, 0] = self.X[i, t]\n",
    "                    self.P_fitness[i] = current_fitness\n",
    "                    if current_fitness < self.g_fitness:\n",
    "                        self.g = self.X[:, t]\n",
    "                        self.g_fitness = current_fitness\n",
    "\n",
    "\n",
    "    def evaluate_initial_decisions_parallel(self):\n",
    "        tasks = [(self.task_data[i % len(self.task_data)], device_computing_capacity[i % len(device_computing_capacity)], 0) for i in range(self.num_devices)]\n",
    "        self.evaluate_fitness_parallel(tasks)\n",
    "\n",
    "    def run(self):\n",
    "        for t in range(self.max_iter):\n",
    "            tasks = [(self.task_data[i % len(self.task_data)], device_computing_capacity[i % len(device_computing_capacity)], t) for i in range(self.num_devices)]\n",
    "            self.evaluate_fitness_parallel(tasks)\n",
    "\n",
    "            # Quantum-inspired position updates for next iteration\n",
    "            for i in range(self.num_devices):\n",
    "                if t < self.max_iter - 1:\n",
    "                    phi = np.random.uniform(0, 1)\n",
    "                    self.X[i, t+1] = np.round(phi * self.P[i, 0] + (1 - phi) * self.g[i]).astype(int)\n",
    "        return self.g\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the best offloading strategies for each number of devices\n",
    "best_offloading_strategies = {}\n",
    "for num_devices in num_devices_list:\n",
    "    qpso = QPSO(num_devices, max_iter=100, task_data=task_data)\n",
    "    best_offloading_strategies[num_devices] = qpso.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50: array([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1]),\n",
       " 100: array([0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0]),\n",
       " 150: array([0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0]),\n",
       " 200: array([1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1]),\n",
       " 250: array([0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0]),\n",
       " 300: array([0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print decisions\n",
    "best_offloading_strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.472944449907652,\n",
       " 2.945888899815304,\n",
       " 4.418833349722957,\n",
       " 5.891777799630608,\n",
       " 7.364722249538261,\n",
       " 8.837666699445913,\n",
       " 10.310611149353566,\n",
       " 11.783555599261216,\n",
       " 13.256500049168869]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_completion_time(x, task_data, bandwidth, noise_power_spectral_density, transmission_power, device_computing_capacity, mec_computing_capacity):\n",
    "    \"\"\"Compute the completion time for task data based on offloading decision.\"\"\"\n",
    "    clock_period = np.mean(clock_period_range)\n",
    "    if x == 0:  # Local computation\n",
    "        local_time_cost = task_data / (device_computing_capacity * 1e9)\n",
    "        local_time_cost *= clock_period\n",
    "        completion_time = local_time_cost\n",
    "    else:  # Edge server computation\n",
    "        transmission_time = task_data / (bandwidth * np.log2(1 + (transmission_power * channel_gain) / (noise_power_spectral_density * bandwidth)))\n",
    "        mec_task_execution_time = task_data / (mec_computing_capacity * 1e9) * clock_period\n",
    "        completion_time = transmission_time + mec_task_execution_time\n",
    "    return completion_time\n",
    "\n",
    "# Calculate the average completion time for each task_data size, assuming uniform offloading decisions across devices\n",
    "avg_completion_times = []\n",
    "for t_data in task_data:\n",
    "    task_size_bits = t_data #* 1e6  # Convert Mbit to bits\n",
    "    completion_times = []\n",
    "    for offloading_decision in best_offloading_strategies[50]:\n",
    "        device_capacity = device_computing_capacity[offloading_decision % len(device_computing_capacity)]\n",
    "        c_time = compute_completion_time(offloading_decision, task_size_bits, bandwidth, noise_power_spectral_density, transmission_power, device_capacity, mec_computing_capacity)\n",
    "        completion_times.append(c_time)\n",
    "    avg_completion_times.append(np.mean(completion_times))\n",
    "\n",
    "avg_completion_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.729444499076521,\n",
       " 29.458888998153043,\n",
       " 44.18833349722957,\n",
       " 58.917777996306086,\n",
       " 73.64722249538261,\n",
       " 88.37666699445914]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average completion time for each task_data size, assuming uniform offloading decisions across devices\n",
    "avg_completion_times = []\n",
    "for d_list in num_devices_list:\n",
    "    #task_size_bits = t_data * 1e6  # Convert Mbit to bits\n",
    "    dev = d_list \n",
    "    completion_times = []\n",
    "    for offloading_decision in best_offloading_strategies[50]:\n",
    "        device_capacity = device_computing_capacity[offloading_decision % len(device_computing_capacity)]\n",
    "        c_time = compute_completion_time(offloading_decision, dev, bandwidth, noise_power_spectral_density, transmission_power, device_capacity, mec_computing_capacity)\n",
    "        completion_times.append(c_time)\n",
    "    avg_completion_times.append(np.mean(completion_times))\n",
    "\n",
    "avg_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[147.29444499076521,\n",
       " 294.58888998153043,\n",
       " 441.8833349722957,\n",
       " 589.1777799630609,\n",
       " 736.472224953826,\n",
       " 883.7666699445914]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average completion time for each task_data size, assuming uniform offloading decisions across devices\n",
    "avg_completion_times = []\n",
    "for rate in transmission_rate:\n",
    "    #task_size_bits = t_data * 1e6  # Convert Mbit to bits\n",
    "    tr = rate \n",
    "    completion_times = []\n",
    "    for offloading_decision in best_offloading_strategies[50]:\n",
    "        device_capacity = device_computing_capacity[offloading_decision % len(device_computing_capacity)]\n",
    "        c_time = compute_completion_time(offloading_decision, tr, bandwidth, noise_power_spectral_density, transmission_power, device_capacity, mec_computing_capacity)\n",
    "        completion_times.append(c_time)\n",
    "    avg_completion_times.append(np.mean(completion_times))\n",
    "\n",
    "avg_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5891750.71963061,\n",
       " 11783501.43926122,\n",
       " 17675252.158891827,\n",
       " 23567002.87852244,\n",
       " 29458753.598153044,\n",
       " 35350504.317783654,\n",
       " 41242255.03741426,\n",
       " 47134005.75704488,\n",
       " 53025756.476675466]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_energy_consumption(x, task_data, transmission_power, device_computing_capacity):\n",
    "    \"\"\"Compute the energy consumption for task data based on offloading decision.\"\"\"\n",
    "    if x == 0:  # Local computation\n",
    "        local_energy_cost = H_m * (device_computing_capacity**2) * task_data\n",
    "        energy_consumption = local_energy_cost\n",
    "    else:  # Edge server computation\n",
    "        transmission_time = task_data / (bandwidth * np.log2(1 + (transmission_power * channel_gain) / (noise_power_spectral_density * bandwidth)))\n",
    "        mec_energy_cost = transmission_power * transmission_time + e_m * task_data\n",
    "        energy_consumption = mec_energy_cost\n",
    "    return energy_consumption\n",
    "\n",
    "# Calculate the average energy consumption for each task_data size, assuming uniform offloading decisions across devices\n",
    "avg_energy_consumptions = []\n",
    "for t_data in task_data:\n",
    "    task_size_bits = t_data * 1e6  # Convert Mbit to bits\n",
    "    energy_consumptions = []\n",
    "    for offloading_decision in best_offloading_strategies[50]:  \n",
    "        device_capacity = device_computing_capacity[offloading_decision % len(device_computing_capacity)]  # Cycle through device capacities\n",
    "        e_consumption = compute_energy_consumption(offloading_decision, task_size_bits, transmission_power, device_capacity)\n",
    "        energy_consumptions.append(e_consumption)\n",
    "    avg_energy_consumptions.append(np.mean(energy_consumptions))\n",
    "\n",
    "avg_energy_consumptions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
